{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dd26ebd-7f50-45e5-a957-3ef5c71b1c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba9c2a2e-585d-48e9-bb20-909f2a8d2af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114708, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('categorized_particles.csv')\n",
    "df.type.values.reshape(-1, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8dab4be-04f3-49b9-b70c-078a54db8683",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(['type','step','experiment'],axis=1).values #'step','experiment','particle_num','particle_id','frame_num','time_stamp_s', 'x_left','x_right','y_top','y_bottom','edge_particle'],axis=1).values\n",
    "Y=df['type'].values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "95871798-50b6-413d-8885-fe66853c7a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[    3     4     1     6     0     3     0     0     0     7     0     0]\n",
      " [    0 12314     0     1     1     2     0     7     0     0     0     0]\n",
      " [    0     4     0     3     0     1     0     1     0     0     0     0]\n",
      " [    0     2     0  1544     2     2     0     2     0     2     0     0]\n",
      " [    0     4     0    15   886     0     0    11     0     0     0     0]\n",
      " [    0     0     0     3     3   102     0     1     0     1     0     0]\n",
      " [    0     0     0     0     0     0   519     0     0     0     0     0]\n",
      " [    0     5     0     2    22     0     0 17486     0     0     0     0]\n",
      " [    0     0     0     0     8     0     0     5     0     0     0     0]\n",
      " [    1     0     0     2     0     0     0     0     0  1411     0     2]\n",
      " [    0     0     0     0     0     0     0     0     0     3     0     0]\n",
      " [    0     0     0     2     0     1     0     0     0     4     0     2]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "         dense fibral       0.75      0.12      0.21        24\n",
      "       dense globular       1.00      1.00      1.00     12325\n",
      "      dense ring-like       0.00      0.00      0.00         9\n",
      "                glass       0.98      0.99      0.99      1554\n",
      "         multi si oil       0.96      0.97      0.96       916\n",
      "              protein       0.92      0.93      0.92       110\n",
      "      schlieren lines       1.00      1.00      1.00       519\n",
      "         silicone oil       1.00      1.00      1.00     17515\n",
      "    silicone oil agg.       0.00      0.00      0.00        13\n",
      "   translucent fibral       0.99      1.00      0.99      1416\n",
      " translucent globular       0.00      0.00      0.00         3\n",
      "translucent ring-like       0.50      0.22      0.31         9\n",
      "\n",
      "             accuracy                           1.00     34413\n",
      "            macro avg       0.67      0.60      0.62     34413\n",
      "         weighted avg       0.99      1.00      1.00     34413\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Random Forest:  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "rfc = RandomForestClassifier(criterion = 'gini', random_state = 0) #42) #'entropy' for shannon entropy to minimize log loss (for classification)\n",
    "rfc.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluating on Training set\n",
    "rfc_pred_test = rfc.predict(X_test)\n",
    "#print('Training Set Evaluation F1-Score=>',f1_score(Y_train,rfc_pred_train,average='micro'))\n",
    "#rfc_cv_score = cross_val_score(rfc, X_test, Y_test, cv=10, scoring='roc_auc')\n",
    "\n",
    "score_train=rfc.score(X_train, Y_train) #, sample_weight=None)\n",
    "score_test=rfc.score(X_test, Y_test) #, sample_weight=None)\n",
    "\n",
    "\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(Y_test, rfc_pred_test))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(Y_test, rfc_pred_test))\n",
    "print('\\n')\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ea862d8a-b469-42c3-b116-4c098bcbf754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9957574172551071\n"
     ]
    }
   ],
   "source": [
    "print(score_train) #\n",
    "print(score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4ba6c733-11d6-4010-af88-de567d5029f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34413"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_pred_test.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "09a1f760-06af-493c-a01b-919070fd0ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.57574172551071\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "\n",
    "for i, estimate in enumerate(rfc_pred_test):\n",
    "    if rfc_pred_test[i]==Y_test[i]:\n",
    "        count=count+1\n",
    "    else:\n",
    "        count=count\n",
    "print((count/len(rfc_pred_test))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee80c05-c710-43ee-a6c8-248d7ad610c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69820ee-33cc-421a-9dbd-e02f3ab53ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "magic functions: timeit # to calculate computing time\n",
    "%timeit(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466a0e99-da73-4ca8-a3ee-89b26de5a5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for loop for anything used twice\n",
    "\n",
    "#function for anything used more than 2 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3db073-0fbb-4ec6-8c05-1bc7c2fba0cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551cf58a-1ab9-4b6b-8b46-e0149aad6f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "types=df['type'].unique()\n",
    "grouped_type=df.groupby(\"type\")\n",
    "\n",
    "list1=[]\n",
    "\n",
    "for i in range(11):\n",
    "    list1.append(grouped_type.get_group(types[i]))\n",
    "\n",
    "for idx, name in enumerate(types):\n",
    "    for i in range(11):\n",
    "        list1.append(grouped_type.get_group(types[i]))\n",
    "    print(\"number of\", name , \"=\", list1[idx].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a8d7cd-671b-4938-8547-480fa73d62f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig=plt.figure(figsize=(8,6))\n",
    "ax1=fig.add_subplot(1,1,1)\n",
    "\n",
    "colors=['red','blue','green','k','orange','purple','cyan','magenta','lavender','yellow','pink','brown']\n",
    "\n",
    "#want to replace this for loop with a function that can be input with any number of particle names or indexes\n",
    "\n",
    "for i in range(len(types)):\n",
    "    ax1.scatter(list1[i]['max_feret_diam_um'], list1[i]['circularity'], s=0.1, color = colors[i], label=types[i])\n",
    "\n",
    "ax1.set_xlabel('max feret diamter (um)')\n",
    "ax1.set_ylabel('circularity')\n",
    "\n",
    "legend=plt.legend(markerscale=15)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
